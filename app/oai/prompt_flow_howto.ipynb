{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stdout\n",
    "%pip install -qU openai\n",
    "%pip install -qU promptflow-tracing\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependancies\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from promptflow.tracing import start_trace\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# for key, value in os.environ.items():\n",
    "#     print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "DEPLOYMENT_NAME = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "\n",
    "# instrument OpenAI\n",
    "start_trace()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Onnyx Runtime doesn\\'t seem to be a recognized term or product in established technology or software domains as of my last update. It is possible you might be referring to a misspelled or less-known technology, product name, or perhaps a newly launched one that didn\\'t exist up to my knowledge cutoff in October 2023. \\n\\nHowever, there is a potential that you could be referring to \"ONNX Runtime\", which is more widely recognized. ONNX Runtime is an open-source high-performance engine for machine learning model inferencing. It is platform-agnostic and can execute ONNX (Open Neural Network Exchange) models â€” which are designed to allow AI developers to use models across different frameworks without needing to recreate them from scratch.\\n\\n### Key Features of ONNX Runtime:\\n1. **Cross-Platform Support**: It works across various hardware and operating systems.\\n2. **Performance**: Optimized for both latency and throughput to provide high performance inferences.\\n3. **Compatibility**: Supports models from popular machine learning frameworks like PyTorch, TensorFlow, and Scikit-Learn via ONNX model conversion.\\n4. **Flexibility**: Can be utilized in a variety of environments, from cloud to edge devices.\\n5. **Community-Driven**: Being open-source, it benefits from contributions and support from a wide community of developers.\\n\\nIf ONNYX Runtime is a newly released product or a term used in a very niche context, I would recommend checking specific databases, official documentation, or industry news sources for the most up-to-date and accurate information.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=DEPLOYMENT_NAME,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert AI assistant, skilled in explaining complex concepts.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"WHAT IS ONNYX RUNTIME\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Underlying Technology:**\n",
    "   - **AutoGen:** Utilizes advanced machine learning models and automation algorithms to automatically generate content, scripts, and workflows. Leverages NLP (Natural Language Processing) to create human-like text.\n",
    "   - **CrewAI:** Employs a combination of AI-driven decision-making engines and collaborative frameworks. Integrates various AI models to assist teams in making data-driven decisions and optimizing project workflows.\n",
    "\n",
    "2. **Performance:**\n",
    "   - **AutoGen:** Typically achieves high efficiency in producing large volumes of content with reasonable accuracy and coherence. Fast generation times, suitable for real-time applications.\n",
    "   - **CrewAI:** Excels in decision-support and project management, potentially slower due to the collaborative and integrative nature but offers high accuracy in recommendations and strategic planning.\n",
    "\n",
    "3. **Flexibility:**\n",
    "   - **AutoGen:** Highly flexible regarding the types of content it can generate, ranging from simple articles to complex scripts. Adaptable to various industry needs but may require fine-tuning for niche-specific jargon.\n",
    "   - **CrewAI:** Offers flexibility in managing diverse projects across different industries by tailoring collaborative strategies and decision-support tools but might need customization to align precisely with unique team structures.\n",
    "\n",
    "4. **Use Cases:**\n",
    "   - **AutoGen:** Ideal for content creation for marketing, journalism, customer support scripts, report generation, and automated messaging. Useful for any domain needing large-scale textual output.\n",
    "   - **CrewAI:** Best suited for team-oriented applications, such as project management, strategic planning, operations optimization, and collaborative platforms. Helpful in environments where decision-making and coordination are critical.\n",
    "\n",
    "5. **User Experience:**\n",
    "   - **AutoGen:** Focuses on ease of use with intuitive interfaces for setting up content parameters and minimal manual input once the model is trained. Users may need to review and tweak generated content for precision.\n",
    "   - **CrewAI:** More interaction-driven with features supporting collaboration, feedback loops, and user inputs. Encourages active participation from team members, which could enhance engagement but may also increase the learning curve.\n",
    "\n",
    "Ultimately, while both 'AutoGen' and 'CrewAI' leverage AI for enhancing productivity, 'AutoGen' focuses on automated content creation, making it an excellent choice for producing large-scale textual materials. On the other hand, 'CrewAI' enhances team collaboration and decision-making, best suited for projects requiring integrated efforts and precise planning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature/Aspect       | AutoGen                                     | CrewAI                                     |\\n|----------------------|---------------------------------------------|--------------------------------------------|\\n| **Primary Purpose**  | Automated text generation                  | Team collaboration and management AI       |\\n| **Core Functionality** | Generating human-like text based on prompts | Assisting in project management and team collaboration |\\n| **Key Technologies** | Natural Language Processing (NLP), Machine Learning | AI-driven project management tools, NLP for communication |\\n| **Use Cases**        | Content creation, fiction writing, chatbots | Managing tasks, scheduling, resource allocation |\\n| **User Interface**   | Text input and output interface            | Dashboard with team collaboration features |\\n| **Customization**    | Customizable via API and settings for specific outputs | Customizable workflows and task management options |\\n| **Integration Options** | Can integrate with various content platforms | Can integrate with project management software like Trello, Asana |\\n| **Market Target**    | Writers, marketers, software developers    | Project managers, team leads, business organizations |\\n| **Strengths**        | High-quality text generation, reducing content creation time | Enhances productivity, efficient resource management |\\n| **Limitations**      | May require supervision to ensure content relevance | May not fully understand complex team dynamics |\\n| **Pricing**          | Subscription-based pricing or per word/token | Subscription-based pricing with tiered plans based on team size |\\n| **Examples of Output** | Articles, blogs, chatbot conversations    | Task lists, schedules, team performance reports |\\n| **Advanced Features** | Context understanding, style adjustments   | Predictive task management, team performance analytics |\\n| **User Experience**  | Straightforward text creation process       | More involved setup and configuration for optimal performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a completion call to generate an answer\n",
    "print(\"Sending a test completion job\")\n",
    "start_phrase = \"Write a tagline for an ice cream shop. \"\n",
    "response = client.completions.create(\n",
    "    model=deployment_name, prompt=start_phrase, max_tokens=10\n",
    ")\n",
    "print(start_phrase + response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Orange who?\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"{response.choices[0].message.role}: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.tracing import start_trace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
